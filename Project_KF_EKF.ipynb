{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping and Perception for an autonomous robot (0510-7951)\n",
    "\n",
    "### 2024/B\n",
    "\n",
    "### Written by Roy Orfaig\n",
    "\n",
    "Exercise 2:\n",
    "---\n",
    "**Part A** (50 points)\n",
    "\n",
    "Localization based on Kalman Filter\n",
    "\n",
    "**Part B** (50 points)\n",
    "\n",
    "Localization based on Extended Kalman Filter\n",
    "\n",
    "\n",
    "-------------------------------------\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Go to [**KITTI dataset**](http://www.cvlibs.net/datasets/kitti/) ,and download your specific records (chose \"sync\" recording)\n",
    "2. Fill in the code the \"TODO\" section\n",
    "2. Answer the question inside the sections\n",
    "3. **Please copy all the results to the report:**\n",
    "  - Outputs- Images, tables, scores,etc\n",
    "  - Performace, analysis and your explanations.\n",
    "  - Attach the completed notebook to the report package.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.patches import Ellipse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import graphs\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from data_preparation import build_LLA_GPS_trajectory,build_GPS_trajectory,add_gaussian_noise,add_gaussian_noise_dict, normalize_angle,normalize_angles_array\n",
    "from utils.misc_tools import error_ellipse\n",
    "from utils.ellipse import draw_ellipse\n",
    "from utils.misc_tools import error_ellipse\n",
    "from utils.ellipse import draw_ellipse\n",
    "from utils.misc_tools import error_ellipse\n",
    "from data_loader import DataLoader\n",
    "from utils.plot_state import plot_state\n",
    "from data_preparation import normalize_angle, normalize_angles_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student name+ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#Student name:Guy Zilberman\n",
    "#ID: 308339274\n",
    "#Record id (kitti): 2011_09_30_drive_0034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change that:\n",
    "random.seed(1)\n",
    "np.random.seed(2)\n",
    "\n",
    "font = {'size': 20}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basedir = \"/home/roy/raw_data\"#\"TODO\" (insert the correct path)\n",
    "date = '2011_10_03'#\"TODO\" (insert  the correct folder)\n",
    "drive = '0042' #\"TODO\" - (insert your correct record number)\n",
    "pwd = os.getcwd()\n",
    "# dat_dir = os.path.join(pwd,\"data\") \n",
    "\n",
    "dataset = DataLoader(basedir, date, drive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graphs(folder=None, file_name=None):\n",
    "    \"\"\"\n",
    "    Saves or shows the current plot\n",
    "    Args:\n",
    "        folder: optional, must be provided with file_name too, the image will be saved to this path with the given file name\n",
    "        file_name: optional, must be provided with folder too, the image will be saved to this path with the given file name\n",
    "    \"\"\"\n",
    "    if not folder or not file_name:\n",
    "        plt.show()\n",
    "    else:\n",
    "        file_name = \"{}/{}.png\".format(folder, file_name)\n",
    "        figure = plt.gcf()  # get current figure\n",
    "        number_of_subplots_in_figure = len(plt.gcf().get_axes())\n",
    "        figure.set_size_inches(number_of_subplots_in_figure * 18, 18)\n",
    "        ram = io.BytesIO()\n",
    "        plt.savefig(ram, format='png', dpi=100)\n",
    "        ram.seek(0)\n",
    "        im = Image.open(ram)\n",
    "        im2 = im.convert('RGB').convert('P', palette=Image.ADAPTIVE)\n",
    "        im2.save(file_name, format='PNG')\n",
    "        plt.close(figure)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A\n",
    "## Localization based on Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the #TODO sections within the KalmanFilter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KalmanFilter:\n",
    "    \"\"\"\n",
    "    class for the implementation of Kalman filter\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, enu_noise, times, vl, vf, sigma_xy, sigma_n, sigma_vx, sigma_vy, k, is_dead_reckoning=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enu_noise: enu data with noise\n",
    "            times: elapsed time in seconds from the first timestamp in the sequence\n",
    "            sigma_xy: sigma in the x and y axis as provided in the question\n",
    "            sigma_vx: sigma in the x velocity\n",
    "            sigma_vy: sigma in the y velocity\n",
    "            sigma_n: hyperparameter used to fine tune the filter\n",
    "            is_dead_reckoning: should dead reckoning be applied after 5.0 seconds when applying the filter\n",
    "            k: The factor kk used to enlarge the initial covariance matrix (this is NOT the gain K_t)\n",
    "        \"\"\"\n",
    "        self.enu_noise = enu_noise\n",
    "        self.times = times\n",
    "        self.sigma_xy = sigma_xy\n",
    "        self.sigma_n = sigma_n\n",
    "        self.sigma_vx = sigma_vx\n",
    "        self.sigma_vy = sigma_vy\n",
    "        self.k = k\n",
    "        self.is_dead_reckoning = is_dead_reckoning\n",
    "        self.starting_time_dead_reck=5 #[seconds]\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the Kalman filter\n",
    "\n",
    "        outputs: enu_kf, covs\n",
    "        \"\"\"\n",
    "        # Note: set the type of conavinces as dtype='float32' , use numpy\n",
    "        B = #\"TODO\" (hint- zeros matrix)\n",
    "        C = #\"TODO\" Define observation matrix\n",
    "        P0 =#\"TODO\" Define initial covariance matrix , dont forget to multiply the sigma with k (self.k)\n",
    "             # hint( use self.sigma_xy,self.sigma_vx,self.sigma_vy and self.k)\n",
    "        Q = #\"TODO\" Define measurement covariance matrix\" (hint- use self.sigma_xy)\n",
    "\n",
    "         # Kalman Filter initialization  #TODO\n",
    "        muo_tO = [#TODO (initial x) ,#TODO (initial vx) , #TODO (initial y), #TODO (initial vy)]\n",
    "        sigma_t_minus1 = #TODO (hint - use P0)\n",
    "            \n",
    "        # Run Kalman filter \n",
    "        locations_kf = []\n",
    "        sigma_kf = []\n",
    "            \n",
    "        for idx, (enu_point, curr_timestemp) in enumerate(zip(self.enu_noise,self.times)):\n",
    "            if idx == 0: # stage 0\n",
    "               ## Kalman Filter initialization (t=0)       \n",
    "                muo_t_minus1 = np.array(muo_tO)\n",
    "                start_timestemp = curr_timestemp\n",
    "                prev_timestemp = curr_timestemp\n",
    "                locations_kf.append(muo_t_minus1[0::2]) #extract x and y from the state vector\n",
    "                sigma_kf.append(sigma_t_minus1)\n",
    "                continue\n",
    "\n",
    "            # Extract Noisy Measurement(x,y)\n",
    "            z_t = np.array([enu_point[0], enu_point[1]]) \n",
    "            delta_t = (curr_timestemp - prev_timestemp).total_seconds()\n",
    "            time_since_start = (curr_timestemp - start_timestemp).total_seconds()\n",
    "            \n",
    "            A = #TODO: Define the transition matrix, (hint- use delta_t)\n",
    "    \n",
    "            R = # TODO: Define process covariance matrix (hint- use self.sigma_n and delta_t), \n",
    "         \n",
    "            \n",
    "            # Kalman Filter mechanizm: Hint: Use matrix multiplication (@ operator)\n",
    "            \n",
    "            muo_t_bar = #\"TODO\" Predicted state estimate (hint  use: A, muo_t_minus1 ,B)\n",
    "            sigma_t_bar =#\"TODO\" Predicted state covariance (hint  use: A ,sigma_t_minus1 ,A ,R)\n",
    "\n",
    "            K_t = #\"TODO\" Calculate Kalman gain (hint- use sigma_t_bar ,C.T ,C , sigma_t_bar C.T ,Q)\n",
    "            \n",
    "            if time_since_start >= self.starting_time_dead_reck and self.is_dead_reckoning:\n",
    "                K_t = #\"TODO\" (hint- set zero the kalman gain)\n",
    "                \n",
    "            muo_t =   #\"TODO\"  Update state estimate (hint- use muo_t_bar , K_t , ,z_t ,C ,muo_t_bar)\n",
    "            sigma_t = #\"TODO\" Update state covariance (hint- use (np.eye(4) , K_t , C, ,sigma_t_bar )\n",
    "\n",
    "            muo_t_minus1 = muo_t\n",
    "            prev_timestemp = curr_timestemp\n",
    "            sigma_t_minus1 = sigma_t\n",
    "            locations_kf.append(muo_t[0::2]) #extract x and y from the state vector\n",
    "            sigma_kf.append(sigma_t)\n",
    "\n",
    "        return np.array(locations_kf),np.array(sigma_kf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the #TODO sections within the ProjectQuestions1 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectQuestions1:\n",
    "    def __init__(self, dataset,display_results,animation_results):\n",
    "        \"\"\"\n",
    "        Given a Loaded Kitti data set with the following ground truth values: tti dataset and adds noise to GT-gps values\n",
    "        - lat: latitude [deg]\n",
    "        - lon: longitude [deg]\n",
    "        - yaw: heading [rad]\n",
    "        - vf: forward velocity parallel to earth-surface [m/s]\n",
    "        - wz: angular rate around z axis [rad/s]\n",
    "        Builds the following np arrays:\n",
    "        - enu - lla converted to enu data\n",
    "        - times - for each frame, how much time has elapsed from the previous frame\n",
    "        - yaw_vf_wz - yaw, forward velocity and angular change rate\n",
    "        - enu_noise - enu with Gaussian noise (sigma_xy=3 meters)\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.display_results = display_results\n",
    "        self.animation_results=animation_results\n",
    "        self.enu, self.times, self.yaw_vf_vl_wz = build_GPS_trajectory(dataset)\n",
    "        self.location_GT = self.enu[:,0:2]\n",
    "        # # # add noise to the trajectory\n",
    "        self.sigma_xy = #\"TODO\"  Set value for sigma_xy\n",
    "        self.sigma_vx = # \"TODO\" Set value for sigma_vx\n",
    "        self.sigma_vy = #\"TODO\"  Set value for sigma_vy\n",
    "        self.sigma_n = #\"TODO\"   Set value for sigma_n \n",
    "        self.k = #\"TODO\"         Set value for k\n",
    "        \n",
    "        \n",
    "        e_nosied, n_noised, u_noised = # add_gaussian_noise(hint- use \"add_gaussian_noise\" function self.enu self.sigma_xy)_xy)\n",
    "        # for example: add_gaussian_noise(x,sigma),\n",
    "        \n",
    "        self.enu_noise = np.stack([e_nosied, n_noised, u_noised], axis=-1)\n",
    "\n",
    "        self.sigma_theta =  #\"TODO\"  Set value for sigma_theta\n",
    "        self.sigma_vf =  #\"TODO\"     Set value for sigma_vf\n",
    "        self.sigma_wz =  #\"TODO\"     Set value for sigma_wz\n",
    "\n",
    "        self.fig_dir_path = os.getcwd() + \"/Results_Q1/\"\n",
    "        if not os.path.exists(self.fig_dir_path):\n",
    "            os.makedirs(self.fig_dir_path)\n",
    "            \n",
    "    @staticmethod\n",
    "    def calc_RMSE_maxE(X_Y_GT, X_Y_est):\n",
    "        \"\"\"\n",
    "        That function calculates RMSE and maxE\n",
    "\n",
    "        Args:\n",
    "            X_Y_GT (np.ndarray): ground truth values of x and y\n",
    "            X_Y_est (np.ndarray): estimated values of x and y\n",
    "\n",
    "        Returns:\n",
    "            (float, float): RMSE, maxE\n",
    "        \"\"\"\n",
    "      \n",
    "        starting_point=100  #TODO Set the starting point for calculations\n",
    "        maxE = -1 # Initialize max error variable\n",
    "        num_of_elements = 0 #Initialize count of elements\n",
    "        e_squared_list = [] # List to store squared errors\n",
    "        err_x_arr = []     # List to store errors in x\n",
    "        err_y_arr = []     # List to store errors in y\n",
    "        for idx in range(X_Y_GT.shape[0]):\n",
    "            e_x = #TODO Calculate error in x (hint use X_Y_GT[idx,0] , X_Y_est[idx,0] )\n",
    "            e_y = #TODO Calculate error in y (hint use X_Y_GT[idx,1] , X_Y_est[idx,1] )\n",
    "            err_x_arr.append(e_x)\n",
    "            err_y_arr.append(e_y)\n",
    "            if idx>starting_point:\n",
    "                e_squared_list.append(###)  #TODO calculate squared error (hint- use e_x,e_y)\n",
    "                curr_E =   #TODO  Calculate current error (hint- use e_x,e_y)\n",
    "                if curr_E > maxE:  # Update max error\n",
    "                    maxE = curr_E   \n",
    "                num_of_elements+=1 \n",
    "        RMSE =   #TODO  Calculate RMSE (hint use e_squared_list,num_of_elements) )\n",
    "        \n",
    "        return RMSE, maxE, np.array(err_x_arr), np.array(err_y_arr)\n",
    "\n",
    "    def Q1(self):\n",
    "        \"\"\"\n",
    "        That function runs the code of question 1 of the project.\n",
    "        Load data from the KITTI dataset, add noise to the ground truth GPS values, and apply a Kalman filter to the noisy data (enu).\n",
    "        \"\"\"\n",
    "        locations_GT = self.enu[:,0:2]\n",
    "        \n",
    "        # b, c\n",
    "        lla_coordinates = build_LLA_GPS_trajectory(self.dataset)\n",
    "        if self.display_results:\n",
    "\n",
    "            graphs.plot_trajectory_and_height(lla_coordinates, \"Longitude Latitude world coordinate trajectory\", 'longitude[deg]', 'latitude[deg]',\n",
    "                                    \"Altitude per frame in the world coordinate trajectory\", 'frame[Number]', 'Altitude[m]')\n",
    "            save_graphs(self.fig_dir_path,\"ground-truth GPS trajectory LLA\")\n",
    "\n",
    "          \n",
    "\n",
    "            graphs.plot_trajectory_and_height(self.enu, \"X-East Y-North coordinate trajectory\", 'X-East[m]', 'Y-North[m]',\n",
    "                                    \"Height per frame in X Y coordinate trajectory\", 'frame[Number]', 'Height[m]')\n",
    "            save_graphs(self.fig_dir_path,\"ground-truth GPS trajectory ENU\")\n",
    "            \n",
    "            # d\n",
    "            # Add a gaussian noise to the ground-truth GPS data\n",
    "            graphs.plot_trajectory_with_noise(self.enu,np.stack([self.enu_noise[:,0], self.enu_noise[:,1]],axis=-1),'Trajectory in local coordinates(ENU) with and without noise','X-East[m]', 'Y-North[m]','GT Trajectory(ENU)','Noised Trajectory(ENU)')\n",
    "            save_graphs(self.fig_dir_path,\"Comparison of the ENU path with and noise\")\n",
    "\n",
    "        ### e. calibration of kalman filter ###\n",
    "        sigma_n_values = #TODO- use linspace\n",
    "        Rmse_vec = []; maxE_vec = []\n",
    "        for sigma_n in sigma_n_values:\n",
    "                  kf = KalmanFilter(self.enu_noise,\n",
    "                                    self.dataset.get_timestamps(),\n",
    "                                    self.yaw_vf_vl_wz[:,1],\n",
    "                                    self.yaw_vf_vl_wz[:,2],\n",
    "                                    self.sigma_xy,\n",
    "                                    sigma_n,\n",
    "                                    self.sigma_vx,\n",
    "                                    self.sigma_vy,\n",
    "                                    self.k,\n",
    "                                    False)\n",
    "            \n",
    "            locations_kf, kf_sigma = kf.run()\n",
    "            RMSE, maxE, err_x_arr, err_y_arr = ProjectQuestions1.calc_RMSE_maxE(locations_GT, locations_kf)\n",
    "            Rmse_vec.append(RMSE)\n",
    "            maxE_vec.append(maxE)\n",
    "\n",
    "        min_idx_rmse = np.argmin(Rmse_vec)\n",
    "        min_idx_maxE = np.argmin(maxE_vec)\n",
    "\n",
    "        fig_e, axes_e =  plt.subplots(1, 2, figsize=(12, 8))\n",
    "        axes_e[0].plot(sigma_n_values, Rmse_vec)\n",
    "        axes_e[0].scatter(sigma_n_values[min_idx_rmse], Rmse_vec[min_idx_rmse])\n",
    "        axes_e[0].set_title('RMSE vs sigma_n values \\n min for sigma_n = '+str(round(sigma_n_values[min_idx_rmse], 3)))\n",
    "        axes_e[0].set(xlabel='sigma_n', ylabel='Rmse [m]')\n",
    "        axes_e[0].grid()\n",
    "        axes_e[1].plot(sigma_n_values, maxE_vec)\n",
    "        axes_e[1].scatter(sigma_n_values[min_idx_maxE], maxE_vec[min_idx_maxE])\n",
    "        axes_e[1].set_title('maxE vs sigma_n values \\n min for sigma_n = '+str(round(sigma_n_values[min_idx_maxE],3)))\n",
    "        axes_e[1].set(xlabel='sigma_n', ylabel='maxE [m]')\n",
    "        axes_e[1].grid()\n",
    "        fig_e.tight_layout()\n",
    "        file_name = \"{}/{}.png\".format(self.fig_dir_path, f\"Kalman_filter_calibration\")\n",
    "        fig_e.savefig(file_name)\n",
    "       \n",
    "       \n",
    "        # f - Kalman\n",
    "        # Dead Reckoning OFF\n",
    "        \n",
    "        kalman_filter = KalmanFilter(self.enu_noise,\n",
    "                                     self.dataset.get_timestamps(),\n",
    "                                     self.yaw_vf_vl_wz[:,1],\n",
    "                                     self.yaw_vf_vl_wz[:,2],\n",
    "                                     self.sigma_xy,\n",
    "                                     self.sigma_n,\n",
    "                                     self.sigma_vx,\n",
    "                                     self.sigma_vy,\n",
    "                                     self.k,\n",
    "                                     False)\n",
    "\n",
    "        locations_kf, kf_sigma = kalman_filter.run()\n",
    "        self.locations_kf = locations_kf\n",
    "    \n",
    "        if self.display_results:\n",
    "            # build_ENU_from_GPS_trajectory\n",
    "            graphs.plot_trajectory_comparison(locations_GT,locations_kf)#,'KF predicted Trajectory in local coordinates(ENU) with and without noise','X-East[m]', 'Y-North[m]','GT Trajectory(ENU)','KF predicted Trajectory(ENU)')\n",
    "            save_graphs(self.fig_dir_path, f\"Comparison of the ground truth trajectory and the filtered trajectory (KF)\")\n",
    "\n",
    "\n",
    "        #RMSE, maxE, err_x_arr, err_y_arr \n",
    "        RMSE, maxE, err_x_arr, err_y_arr = ProjectQuestions1.calc_RMSE_maxE(locations_GT, locations_kf)\n",
    "\n",
    "        # Dead Reckoning ON\n",
    "        kalman_filter = KalmanFilter(self.enu_noise,\n",
    "                                     self.dataset.get_timestamps(),\n",
    "                                     self.yaw_vf_vl_wz[:,1],\n",
    "                                     self.yaw_vf_vl_wz[:,2],\n",
    "                                     self.sigma_xy,\n",
    "                                     self.sigma_n,\n",
    "                                     self.sigma_vx,\n",
    "                                     self.sigma_vy,\n",
    "                                     self.k,\n",
    "                                     True)\n",
    "\n",
    "        locations_kf_dr, kf_sigma_dr = kalman_filter.run()\n",
    "        locations_GT = self.enu[:,0:2]\n",
    "\n",
    "        if self.display_results:\n",
    "          \n",
    "            print(f'maxE={maxE}, RMSE={RMSE}')\n",
    "            graphs.plot_trajectory_comparison_dead_reckoning(locations_GT, locations_kf, locations_kf_dr)\n",
    "            save_graphs(self.fig_dir_path, f\"trajectory_comparison_dead_reckoning\")\n",
    "            graphs.plot_error([err_x_arr,np.sqrt(kf_sigma[:,0,0])],[err_y_arr,np.sqrt(kf_sigma[:,2,2])])\n",
    "            save_graphs(self.fig_dir_path, f\"plot_trajectory_error\")\n",
    "\n",
    "        if self.animation_results:\n",
    "            print(\"wait...\")\n",
    "            ani = graphs.build_animation(locations_GT, locations_kf_dr, locations_kf, kf_sigma[:, ::2, ::2].reshape(kf_sigma.shape[0], -1),'KF Trajectory estimation - constant velocity with dead reckoning', 'X-East[m]', 'Y-North[m]', 'GT', 'Dead Reckoning', 'KF') #hint- graphs.build_animation)\n",
    "           \n",
    "            graphs.save_animation(ani, self.fig_dir_path, \"kf_predict_with_dead_reckoning\")\n",
    "            print(\"Done!\")\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    def run(self):\n",
    "        self.Q1()  \n",
    "        print(\"Successfully finished. All data saved in {}\".format(self.fig_dir_path))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Kalman Filter!\n",
    "\n",
    "display_results=True\n",
    "animation_results=True\n",
    "\n",
    "project = ProjectQuestions1(dataset,display_results,animation_results)\n",
    "project.run()\n",
    "locations_kf=project.locations_kf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B\n",
    "## Localization based on Extended Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the #TODO sections within the ExtendedKalmanFilter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedKalmanFilter:\n",
    "    \"\"\"\n",
    "    class for the implementation of the extended Kalman filter\n",
    "    \"\"\"\n",
    "    def __init__(self, enu_noise, yaw_vf_wz_noise, times, sigma_xy, sigma_theta, sigma_vf, sigma_wz, k, is_dead_reckoning, dead_reckoning_start_sec=5.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            enu_noise: enu data with noise\n",
    "            times: elapsed time in seconds from the first timestamp in the sequence\n",
    "            sigma_xy: sigma in the x and y axis as provided in the question\n",
    "            sigma_n: hyperparameter used to fine tune the filter\n",
    "            yaw_vf_wz: the yaw, forward velocity and angular change rate to be used (either non noisy or noisy, depending on the question)\n",
    "            sigma_theta: sigma of the heading\n",
    "            sigma_vf: sigma of the forward velocity\n",
    "            sigma_wz: sigma of the angular change rate\n",
    "            k: hyper parameter to fine tune the filter\n",
    "            is_dead_reckoning: should dead reckoning be applied after 5.0 seconds when applying the filter\n",
    "            dead_reckoning_start_sec: from what second do we start applying dead reckoning, used for experimentation only\n",
    "        \"\"\"\n",
    "        self.enu_noise = enu_noise\n",
    "        self.yaw_vf_wz_noise = yaw_vf_wz_noise\n",
    "        self.times = times\n",
    "        self.sigma_xy = sigma_xy\n",
    "        self.sigma_theta = sigma_theta\n",
    "        self.sigma_vf = sigma_vf\n",
    "        self.sigma_wz = sigma_wz\n",
    "        self.k = k\n",
    "        self.is_dead_reckoning = is_dead_reckoning\n",
    "        self.dead_reckoning_start_sec = dead_reckoning_start_sec\n",
    "\n",
    "\n",
    "    #TODO\n",
    "    @staticmethod\n",
    "    def calc_RMSE_maxE(X_Y_GT, YAW_GT, X_Y_est, YAW_est):\n",
    "        \"\"\"\n",
    "        That function calculates RMSE and maxE\n",
    "\n",
    "        Args:\n",
    "            X_Y_GT (np.ndarray): ground truth values of x and y\n",
    "            X_Y_est (np.ndarray): estimated values of x and y\n",
    "\n",
    "        Returns:\n",
    "            (float, float): RMSE, maxE\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        start_point=100  #TODO Set the starting point for calculations\n",
    "        maxE = -1   # Initialize max error variable\n",
    "        num_of_elements = 0 #Initialize count of elements\n",
    "        e_squared_list = [] # List to store squared errors\n",
    "        err_x_arr = []  #L ist to store errors in x\n",
    "        err_y_arr = []   # List to store errors in y\n",
    "        err_yaw_arr = [] # List to store errors in yaw\n",
    "        for idx in range(X_Y_GT.shape[0]):\n",
    "            e_x =     #TODO Calculate error in x (hint use GT , kalman results)\n",
    "            e_y =     #TODO Calculate error in y ( hint use GT ,kalman results)\n",
    "            e_yaw =   #TODO Calculate error in yaw ( hint use GT , kalman results)\n",
    "            err_x_arr.append(e_x)\n",
    "            err_y_arr.append(e_y)\n",
    "            err_yaw_arr.append(e_yaw)\n",
    "            if idx>start_point:\n",
    "                e_squared_list.append(##) #TODO calculate squared error (hint use e_x,e_y)\n",
    "                curr_E =  #TODO  Calculate current error (hint use e_x,e_y)\n",
    "                if curr_E > maxE: # Update max error\n",
    "                    maxE = curr_E\n",
    "                num_of_elements+=1\n",
    "\n",
    "        RMSE =  #TODO  Calculate RMSE (hint use e_squared_list,num_of_elements)\n",
    "        return RMSE, maxE, np.array(err_x_arr), np.array(err_y_arr), np.array(err_yaw_arr)\n",
    "    \n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the Kalman filter\n",
    "\n",
    "        outputs: enu_kf, covs\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialization of the initial covariance matrix, P0.\n",
    "        # This matrix represents the initial uncertainty in the state estimation.\n",
    "        # The diagonal elements represent the variances of x, y, and theta respectively.\n",
    "        # Off-diagonal elements are zero indicating no initial correlation between state variables.\n",
    "\n",
    "        P0 = #TODO (hint self.k ,self.sigma_xy * self.sigma_theta , dtype='float32')\n",
    "        \n",
    "         #Measurement matrix, H.\n",
    "        # This matrix maps the state space into the measurement space.\n",
    "        # Here, it is an identity matrix indicating that the state variables are directly observable.\n",
    "        H = #TODO \n",
    "        \n",
    "        G = #TODO (hint- diagonal matrix)\n",
    "            \n",
    "        # Noise process covariance matrix, R.\n",
    "        # This matrix represents the noise in the velocity process.\n",
    "        # The diagonal elements represent the variances of the noises for the forward velocity (vf) and angular velocity (wz) respectively.\n",
    "        R = #TODO (hint- self.sigma_vf,self.sigma_wz, dtype='float32')\n",
    "                    \n",
    "        #optional\n",
    "        R_gal =   np.zeros_like(G)\n",
    "        R_gal[0,0] = 0.00001\n",
    "        R_gal[1,1] = 0.00001\n",
    "        R_gal[2,2] = 0.00001\n",
    "                    \n",
    "        Q = #TODO (hint -use self.sigma_xy ,dtype='float32')\n",
    "                    \n",
    "        # Kalman Filter initialization  #TODO\n",
    "        muo_tO = [#TODO (initial x) ,#TODO (initial y) ,#TODO (initial yaw)]\n",
    "        sigma_t_minus1 = #TODO (hint - use P0)\n",
    "                    \n",
    "                    \n",
    "        locations_kf = []\n",
    "        sigma_kf = []\n",
    "        for idx, (enu_point, curr_timestemp, yaw_vf_wz_noise) in enumerate(zip(self.enu_noise, self.times, self.yaw_vf_wz_noise)):\n",
    "            if idx == 0:\n",
    "                # first step t=0 , initialize Kalman\n",
    "                muo_t_minus1 = np.array(muo_tO)\n",
    "                start_timestemp = curr_timestemp\n",
    "                prev_timestemp = curr_timestemp\n",
    "                sigma_t_minus1 = sigma_0\n",
    "                locations_kf.append(muo_t_minus1)\n",
    "                sigma_kf.append(sigma_t_minus1)\n",
    "                continue\n",
    "\n",
    "            # Extract Noisy Measurement(x,y)\n",
    "            #TODO\n",
    "            z_t = np.array([enu_point[0], enu_point[1]])\n",
    "            delta_t = (curr_timestemp - prev_timestemp).total_seconds()\n",
    "            time_since_start = (curr_timestemp - start_timestemp).total_seconds()\n",
    "            \n",
    "            # Extracting the forward velocity (vf_t) and angular velocity (w_t) from the input noise array.\n",
    "            vf_t = yaw_vf_wz_noise[1]\n",
    "            w_t = yaw_vf_wz_noise[2]\n",
    "            \n",
    "            # Computing the non-linear state transition. This represents the predicted state based on the control inputs (vf_t and w_t) and the previous state estimate (muo_t_minus1).\n",
    "            \n",
    "            non_linear_muo =  #TODO\n",
    "            \n",
    "            # Process noise mapping matrix, V.\n",
    "            # This matrix is updated based on the non-linear state transition.\n",
    "            # It maps the noise in the control inputs to the state space.\n",
    "            \n",
    "            #TODO\n",
    "            V = #TODO\n",
    "                    \n",
    "            # State transition matrix, G.\n",
    "            # This matrix is updated based on the non-linear state transition.\n",
    "            # It represents the partial derivatives of the state transition function with respect to the state variables.\n",
    "                    \n",
    "            #TODO\n",
    "            G[0,2] = #TODO\n",
    "            G[1,2] = #TODO\n",
    "\n",
    "            # prediction\n",
    "                    \n",
    "            muo_t_bar =   #TODO (hint- use muo_t_minus1 , non_linear_muo )\n",
    "            sigma_t_bar = #TODO (hint- G ,sigma_t_minus1 ,G.T , V , R ,V.T , R_gal)\n",
    " ) \n",
    "            # Kalman gain\n",
    "            K_t = #TODO (hint- sigma_t_bar , H.T , H , sigma_t_bar ,H.T , Q) \n",
    "\n",
    "            if time_since_start >= self.dead_reckoning_start_sec and self.is_dead_reckoning:\n",
    "                \n",
    "                K_t = #TODO (hint- zero matrix)\n",
    "            \n",
    "            muo_t =   #TODO (hint- muo_t_bar ,K_t  ,z_t , H , muo_t_bar) \n",
    "            sigma_t = #TODO (hint-np.eye(3) , K_t , H,  sigma_t_bar)   \n",
    "\n",
    "            muo_t_minus1 = muo_t\n",
    "            muo_t_minus1[-1] = normalize_angle(muo_t_minus1[-1])\n",
    "            prev_timestemp = curr_timestemp\n",
    "            sigma_t_minus1 = sigma_t\n",
    "            locations_kf.append(muo_t)\n",
    "            sigma_kf.append(sigma_t)\n",
    "\n",
    "        return np.array(locations_kf), np.array(sigma_kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the #TODO sections within the ProjectQuestions2 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectQuestions2:\n",
    "    def __init__(self, dataset,display_results,save_animation,locations_kf):\n",
    "        \"\"\"\n",
    "        Given a Loaded Kitti data set with the following ground truth values: tti dataset and adds noise to GT-gps values\n",
    "        - lat: latitude [deg]\n",
    "        - lon: longitude [deg]\n",
    "        - yaw: heading [rad]\n",
    "        - vf: forward velocity parallel to earth-surface [m/s]\n",
    "        - wz: angular rate around z axis [rad/s]\n",
    "        Builds the following np arrays:\n",
    "        - enu - lla converted to enu data\n",
    "        - times - for each frame, how much time has elapsed from the previous frame\n",
    "        - yaw_vf_wz - yaw, forward velocity and angular change rate\n",
    "        - enu_noise - enu with Gaussian noise (sigma_xy=3 meters)\n",
    "        - yaw_vf_wz_noise - yaw_vf_wz with Gaussian noise in vf (sigma 2.0) and wz (sigma 0.2)\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.display_results=display_results\n",
    "        self.save_animation=save_animation\n",
    "        self.locations_kf=locations_kf\n",
    "        self.enu, self.times, self.yaw_vf_vl_wz = #TODO (hint- use \"build_GPS_trajectory\" function)\n",
    "        self.location_GT = self.enu[:,0:2]\n",
    "        # # # add noise to the trajectory\n",
    "        self.sigma_xy = #TODO\n",
    "        \n",
    "        e_nosied, n_noised, u_noised =#TODO (hint- use \"add_gaussian_noise\" function,self.enu,self.sigma_xy)\n",
    "        self.enu_noise = np.stack([e_nosied, n_noised, u_noised], axis=-1)\n",
    "\n",
    "        self.sigma_theta = #TODO\n",
    "        self.sigma_vf =  #TODO\n",
    "        self.sigma_wz =  #TODO\n",
    "        self.k =  #TODO\n",
    "\n",
    "        yaw, vf_noised, wz_noised = #TODO (hint- use \"add_gaussian_noise\" function,self.yaw_vf_vl_wz[:, 0],self.sigma_wz)\n",
    "        self.yaw_vf_wz_noise = np.stack([yaw, vf_noised, wz_noised ], axis=-1)\n",
    "        self.fig_dir_path = os.getcwd() + \"/Results_Q2/\"\n",
    "        if not os.path.exists(self.fig_dir_path):\n",
    "            os.makedirs(self.fig_dir_path)\n",
    "\n",
    "    \n",
    "    def Q2(self):\n",
    "\n",
    "        \"\"\"\n",
    "        That function runs the code of question 2 of the project.\n",
    "        Load data from the KITTI dataset, add noise to the ground truth GPS values, yaw rate, and velocities, and apply a Extended Kalman filter to the noisy data.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.display_results:\n",
    "            # c, d, e, f -          # plot vf and wz with and without noise\n",
    "            graphs.plot_yaw_yaw_rate_fv(self.yaw_vf_vl_wz[:,0],self.yaw_vf_vl_wz[:,3],self.yaw_vf_vl_wz[:,1])\n",
    "            save_graphs(self.fig_dir_path,F\"Yaw_Yaw_rate_fv\")\n",
    "\n",
    "            graphs.plot_vf_wz_with_and_without_noise(self.yaw_vf_vl_wz[:,[0,1,3]],self.yaw_vf_wz_noise)\n",
    "            save_graphs(self.fig_dir_path,F\"vf_wz_with_and_without_noise\")\n",
    "\n",
    "        ekf = ExtendedKalmanFilter(self.enu_noise,\n",
    "                                   self.yaw_vf_wz_noise,\n",
    "                                   self.dataset.get_timestamps(),\n",
    "                                   self.sigma_xy,\n",
    "                                   self.sigma_theta,\n",
    "                                   self.sigma_vf,\n",
    "                                   self.sigma_wz,\n",
    "                                   self.k,\n",
    "                                   is_dead_reckoning=False)\n",
    "        \n",
    "        locations_ekf_x_y_yaw, sigma_x_xy_yx_y_t = ekf.run()\n",
    "        locations_ekf = locations_ekf_x_y_yaw[:,0:2]\n",
    "        self.locations_ekf = locations_ekf\n",
    "        RMSE, maxE, err_x_arr, err_y_arr, err_yaw_arr = ekf.calc_RMSE_maxE(self.location_GT, self.yaw_vf_vl_wz[:,0], locations_ekf, locations_ekf_x_y_yaw[:,2])\n",
    "\n",
    "        if self.display_results:\n",
    "            print(f'maxE{maxE}, RMSE={RMSE}')\n",
    "            graphs.plot_trajectory_comparison(self.location_GT,locations_ekf)\n",
    "            save_graphs(self.fig_dir_path,f\"plot_trajectory_comparison\")\n",
    "\n",
    "            graphs.plot_error([err_x_arr,np.sqrt(sigma_x_xy_yx_y_t[:,0,0])],[err_y_arr,np.sqrt(sigma_x_xy_yx_y_t[:,1,1])],[err_yaw_arr,np.sqrt(sigma_x_xy_yx_y_t[:,2,2])])\n",
    "           # save_graphs(self.fig_dir_path,\"ground-truth GPS trajectory ENU\")\n",
    "            save_graphs(self.fig_dir_path,f\"plot_error_EKF_vs_GT\")\n",
    "\n",
    "        ekf = ExtendedKalmanFilter(self.enu_noise,\n",
    "                                   self.yaw_vf_wz_noise,\n",
    "                                   self.dataset.get_timestamps(),\n",
    "                                   self.sigma_xy,\n",
    "                                   self.sigma_theta,\n",
    "                                   self.sigma_vf,\n",
    "                                   self.sigma_wz,\n",
    "                                   self.k,\n",
    "                                   is_dead_reckoning=True)\n",
    "\n",
    "        locations_ekf_dr, ekf_sigma_dr = ekf.run()\n",
    "        locations_ekf_dr_x_y_yaw, ekf_sigma_dr = ekf.run()\n",
    "        locations_ekf_dr = locations_ekf_dr_x_y_yaw[:,0:2]\n",
    "\n",
    "        if self.display_results:\n",
    "            graphs.plot_trajectory_comparison_dead_reckoning(self.location_GT, locations_ekf, locations_ekf_dr)\n",
    "            save_graphs(self.fig_dir_path,f\"plot_trajectory_comparison_dead_reckoning\")\n",
    "            graphs.plot_trajectory_comparison_kf_ekf(self.location_GT, self.locations_ekf, self.locations_kf)\n",
    "            save_graphs(self.fig_dir_path,f\"trajectory_comparison_kf_ekf\")\n",
    "     \n",
    "\n",
    "        if self.save_animation:\n",
    "            print(\"wait...\")\n",
    "            ani = graphs.build_animation(self.location_GT, locations_ekf_dr, locations_ekf, sigma_x_xy_yx_y_t[:, :2, :2].reshape(sigma_x_xy_yx_y_t.shape[0], -1),'EKF Trajectory estimation - constant velocity with dead reckoning', 'X-East[m]', 'Y-North[m]', 'GT', 'Dead Reckoning', 'EKF') #hint- graphs.build_animation)\n",
    "            \n",
    "            graphs.save_animation(ani, self.fig_dir_path, \"EKF_predict_with_dead_reckoning\")\n",
    "            print(\"Done!...\")\n",
    "            plt.close()\n",
    "\n",
    "    def get_odometry(self, sensor_data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sensor_data: map from a tuple (frame number, type) where type is either ‘odometry’ or ‘sensor’.\n",
    "            Odometry data is given as a map containing values for ‘r1’, ‘t’ and ‘r2’ – the first angle, the translation and the second angle in the odometry model respectively.\n",
    "            Sensor data is given as a map containing:\n",
    "              - ‘id’ – a list of landmark ids (starting at 1, like in the landmarks structure)\n",
    "              - ‘range’ – list of ranges, in order corresponding to the ids\n",
    "              - ‘bearing’ – list of bearing angles in radians, in order corresponding to the ids\n",
    "\n",
    "        Returns:\n",
    "            numpy array of of dim [num of frames X 3]\n",
    "            first two components in each row are the x and y in meters\n",
    "            the third component is the heading in radians\n",
    "        \"\"\"\n",
    "        num_frames = len(sensor_data) // 2\n",
    "        state = np.array([[0, 0, 0]], dtype=float).reshape(1, 3)\n",
    "        for i in range(num_frames):\n",
    "            curr_odometry = sensor_data[i, 'odometry']\n",
    "            t = np.array([\n",
    "                curr_odometry['t'] * np.cos(state[-1, 2] + curr_odometry['r1']),\n",
    "                curr_odometry['t'] * np.sin(state[-1, 2] + curr_odometry['r1']),\n",
    "                curr_odometry['r1'] + curr_odometry['r2']\n",
    "            ]).reshape(3, 1)\n",
    "            new_pos = state[-1, :].reshape(3, 1) + t\n",
    "            state = np.concatenate([state, new_pos.reshape(1, 3)], axis=0)\n",
    "        return state\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "        self.Q2()\n",
    "        print(\"Successfully finished. All data saved in {}\".format(self.fig_dir_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results=True\n",
    "save_animation=True\n",
    "project = ProjectQuestions2(dataset,display_results,save_animation,locations_kf)\n",
    "project.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project2",
   "language": "python",
   "name": "project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "22d54b2afd460569b9e9050ca66571082a0929281e5b28d20c6fd75528a62769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
